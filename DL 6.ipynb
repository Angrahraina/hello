{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1043591879.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    6.object detection using tensorflow\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "6.object detection using tensorflow\n",
    "obj-to load pretrained model and prove performace by transfer learning\n",
    "Object detection is a computer vision task that involves locating and identifying objects within an image or a video. TensorFlow, an open-source deep learning framework developed by Google, provides various tools and pre-trained models to perform object detection efficiently. Here is an overview of the steps to perform object detection using TensorFlow:\n",
    "\n",
    "Object detection is a computer vision task that involves locating and identifying objects within an image or a video. TensorFlow, an open-source deep learning framework developed by Google, provides various tools and pre-trained models to perform object detection efficiently. Here is an overview of the steps to perform object detection using TensorFlow:\n",
    "\n",
    "Installation and Setup:\n",
    "\n",
    "Install TensorFlow: You can install TensorFlow using pip, Anaconda, or by building it from source.\n",
    "Install other necessary libraries, such as OpenCV, if not already installed.\n",
    "Choose a Pre-trained Object Detection Model:\n",
    "TensorFlow provides a selection of pre-trained object detection models. You can choose from models like Faster R-CNN, SSD (Single Shot MultiBox Detector), YOLO (You Only Look Once), and others, depending on your requirements.\n",
    "\n",
    "Download the Model:\n",
    "Download the pre-trained model and its associated configuration file from the TensorFlow Model Zoo. The Model Zoo provides pre-trained models for various architectures and datasets.\n",
    "\n",
    "Set Up the Object Detection Pipeline:\n",
    "Create a Python script or Jupyter Notebook to set up the object detection pipeline. Here are the typical steps involved:\n",
    "\n",
    "Import the required libraries, including TensorFlow and OpenCV.\n",
    "Load the pre-trained model using the TensorFlow Object Detection API.\n",
    "Load the model's configuration file and checkpoint.\n",
    "Prepare the input image or video stream for inference.\n",
    "Inference:\n",
    "Perform object detection on your input data (image or video) using the pre-trained model:\n",
    "\n",
    "Preprocess the input data as required by the model (e.g., resizing, normalization).\n",
    "Pass the input data through the model to obtain object detection results.\n",
    "Post-process the model's output to extract bounding box coordinates, class labels, and confidence scores.\n",
    "Visualize and Interpret Results:\n",
    "\n",
    "Draw bounding boxes around detected objects in the input image or video.\n",
    "Display the class labels and confidence scores for each detected object.\n",
    "Optional: Real-time Object Detection:\n",
    "If you are working with a video stream or webcam, you can apply the object detection pipeline to each frame in real-time. OpenCV is a useful library for handling video feeds and real-time object detection.\n",
    "\n",
    "Customization (Optional):\n",
    "If your application requires object detection for specific classes or objects not covered by the pre-trained models, you may fine-tune an existing model on your dataset using transfer learning.\n",
    "\n",
    "Deployment:\n",
    "Once you have developed and tested your object detection pipeline, you can deploy it in your application or system, whether it's a standalone program, a mobile app, or an embedded system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IdE6hPgKCZzn"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mImage\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMSePWMcZWAR"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lE48QiIC_cl"
   },
   "outputs": [],
   "source": [
    "Image_Shape = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqXwzZm9DDZI"
   },
   "outputs": [],
   "source": [
    "URL_dataset = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UV0dS1jqDZm8",
    "outputId": "8f67e753-ee7e-48bc-f6e4-afafc4314c16"
   },
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(origin = URL_dataset, fname='flower_photos' ,untar= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "QHz60UtjEPAm",
    "outputId": "1aa06784-f42b-4f12-f1c0-d07e3edcbc45"
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(data_dir)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "q1fVm2LkOCFt",
    "outputId": "10eb9eff-aed7-40a5-9a30-35fa688c5d61"
   },
   "outputs": [],
   "source": [
    "'''data_dir = pathlib.Path(data_dir)\n",
    "file_list = list(data_dir.glob('*/*.jpg'))\n",
    "half_file_list = file_list[:len(file_list) // 2]\n",
    "#image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count = len(half_file_list)\n",
    "print(image_count)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tb_OdpdBEpYk"
   },
   "outputs": [],
   "source": [
    "flowers_images_dict = {\"daisy\" : list(data_dir.glob('daisy/*')),\n",
    "                      \"dandelion\" : list(data_dir.glob('dandelion/*')),\n",
    "                      \"roses\" : list(data_dir.glob('roses/*')),\n",
    "                      \"sunflowers\" : list(data_dir.glob('sunflowers/*')),\n",
    "                      \"tulips\" : list(data_dir.glob('tulips/*'))}\n",
    "\n",
    "flowers_labels_dict = {\"daisy\" : 0,\n",
    "                       \"dandelion\" : 1,\n",
    "                       \"roses\" : 2,\n",
    "                       \"sunflowers\" : 3,\n",
    "                       \"tulips\" : 4}\n",
    "\n",
    "X, Y = [],[]\n",
    "\n",
    "for flower_name, images in flowers_images_dict.items():\n",
    "  for image in images:\n",
    "    img = cv2.imread(str(image))\n",
    "    resized_img = cv2.resize(img, Image_Shape)\n",
    "    X.append(resized_img)\n",
    "    Y.append(flowers_labels_dict[flower_name])\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdalRzLXG2P5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5yam13cHOi4"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=0)\n",
    "X_train_scaled = X_train/255\n",
    "X_test_scaled = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fqndgb0sHuuY"
   },
   "outputs": [],
   "source": [
    "tf_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHU3LivvIAbX"
   },
   "outputs": [],
   "source": [
    "classifier = tf.keras.Sequential([hub.KerasLayer(tf_model, input_shape = (224,224,3), trainable=False),\n",
    "tf.keras.layers.Dense(len(flowers_labels_dict), activation = \"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "JcWb8kXaJaja",
    "outputId": "9c9670b5-3d2a-4744-dcde-d4a489f60c76"
   },
   "outputs": [],
   "source": [
    "classifier.summary()\n",
    "classifier.compile(optimizer=\"adam\",\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "y3-b9LrzN5RN",
    "outputId": "4e21b5ce-f7cd-4f59-9730-9a646c3bfe6a"
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_test_scaled, Y_test, epochs = 5)\n",
    "#classifier.evaluate(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "AgWznt92SKHx",
    "outputId": "a847d396-62b0-49d5-e1fd-80c43c714740"
   },
   "outputs": [],
   "source": [
    "classifier.evaluate(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "xqMCvZclSLHH",
    "outputId": "208785f2-f1af-434f-f17c-f4c974969733"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open()\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZaFJpwZUBd2"
   },
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.img_to_array(img.resize(Image_Shape))\n",
    "img = np.array([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "L80ZLRXcXE3W",
    "outputId": "6ac97fee-1a8b-4606-d40e-4d91e5423451"
   },
   "outputs": [],
   "source": [
    "res = classifier.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4Nq43i04XJrX",
    "outputId": "ec0d8062-a06b-49c3-efa7-f0452d434c11"
   },
   "outputs": [],
   "source": [
    "print(\"The prediction is : {}\".format(list(flowers_labels_dict.keys())[np.argmax(res)]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
